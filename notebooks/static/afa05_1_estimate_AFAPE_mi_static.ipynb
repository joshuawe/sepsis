{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767b7864-b3cf-4539-8227-c6de2ef7c792",
   "metadata": {},
   "source": [
    "# (5.1) Solve AFAPE for dataset completed with multiple imputation\n",
    "Use an estimator to evaluate E[C|do(R_bar = 1)]. Also give valid confidence intervals (through estimating mean and variance). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b810b65-dcaa-4ad0-b0ed-cf3737fd8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96136052-0cbe-41a9-a69f-5e2de963a509",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a07dc-1698-417c-9d75-a8d6323ca320",
   "metadata": {},
   "source": [
    "Paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44057c6d-6463-4519-804d-df2c37279cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.configurations.utils_static import specify_default_paths_static\n",
    "# which dataset to work on \n",
    "dataset_name   = \"synthetic_1\"\n",
    "\n",
    "# name for of missingness scenario \n",
    "miss_scenario  = 'MCAR_1'\n",
    "\n",
    "# automatically specify some path locations (change paths manually if needed) \n",
    "paths = specify_default_paths_static(dataset_name = dataset_name , miss_scenario = miss_scenario) \n",
    "\n",
    "# name for agent \n",
    "agent_name            = 'DQN'\n",
    "agent_dir = paths['data_dir'] + 'afa_agents' + '/' + agent_name + '/'\n",
    "\n",
    "# how to name the afa_dataset\n",
    "mi_model_name   =  'mi_simple'\n",
    "mi_model_dir  =  paths['data_dir'] + 'mi_models/' + mi_model_name + '/'\n",
    "afa_dataset_name = mi_model_name "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04782040-9ef5-43e6-99b3-fc997fe88a62",
   "metadata": {},
   "source": [
    "## Load afa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9d62da-8b4f-48e7-9f39-a635a95b65ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 16:49:15.770346: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 16:49:15.898295: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:15.898349: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 16:49:16.555553: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:16.555668: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:16.555677: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from afa.data_modelling.datasets.data_loader.data_loader_static import DataLoader_static\n",
    "from afa.data_modelling.missingness.multiple_imputation.multiple_imputed_data_loader.multiple_imputed_data_loader_static import MultipleImputedDataLoader_static\n",
    "from afa.afa_datasets.afa_data_loader.afa_data_loader_static import AFADataLoader_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d3a81d-4bdf-4286-9645-097cee851433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "data_loader = DataLoader_static( data_file                  = paths['data_file'],\n",
    "                                 superfeature_mapping_file  = paths['superfeature_mapping_file'],\n",
    "                                 problem_file               = paths['problem_file'],\n",
    "                                 afa_problem_files          = paths['afa_problem_files'], \n",
    "                                 folds_file                 = paths['folds_file'] )\n",
    "dataset = data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34c5fa1-0839-445a-b90a-5f9cc98cff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mi dataset\n",
    "augmented_data_file = mi_model_dir + 'results.hkl'\n",
    "mi_model_params = None\n",
    "mi_data_loader = MultipleImputedDataLoader_static(                   \n",
    "                    augmented_data_file = augmented_data_file,\n",
    "                    dataset             = dataset,\n",
    "                    model_params        = mi_model_params) \n",
    "mi_dataset = mi_data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5067e4d-de37-4fd6-8799-e783ad4792d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 16:49:22.192272: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-27 16:49:22.192418: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:22.192486: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:22.192545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:22.192602: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:22.192659: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:22.192736: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:22.192798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:22.192855: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 16:49:22.192864: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 16:49:22.193293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#load afa_dataset\n",
    "augmented_data_file = agent_dir + afa_dataset_name + '_' + 'results.hkl'\n",
    "afa_agent_params = None\n",
    "afa_data_loader = AFADataLoader_static(                   \n",
    "                    augmented_data_file = augmented_data_file,\n",
    "                    dataset             = mi_dataset,\n",
    "                    model_params        = afa_agent_params) \n",
    "afa_dataset = afa_data_loader.load() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c599147-ed2f-43a3-bba9-6d64167aa075",
   "metadata": {},
   "source": [
    "## Compute estimates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b388127c-1e11-4b50-86b5-3b68ac93baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_datasets/afa_dataset_static.py\u001b[0m(274)\u001b[0;36mestimate_counterfactual_cost_mi\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    272 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    273 \u001b[0;31m        \u001b[0;31m# compute bootstraps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 274 \u001b[0;31m        \u001b[0mJ_bootstraps\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    275 \u001b[0;31m        \u001b[0mJ_bootstraps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmi_model_name\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mJ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_bootstraps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    276 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "J_bootstraps = afa_dataset.estimate_counterfactual_cost_mi(  mi_model_name  = mi_model_name , \n",
    "                                                             fold = 0, split = \"val\", \n",
    "                                                             n_samples = None, \n",
    "                                                             n_bootstraps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a78cb0c6-cb9e-4747-b91c-cfe3922d111f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mi_simple': array([1.86039031, 2.25157695, 1.44828481, 1.93997693, 2.11311716,\n",
       "        1.67076759, 1.9676605 , 2.29518835, 1.06887482, 1.65833719])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_bootstraps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb44b918-5f45-41a3-9fff-00c1f24b49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save estimate\n",
    "from afa.afa_models.afa_estimators.utils import save_results_bootstrapping\n",
    "save_results_bootstrapping( J_bootstraps , agent_dir, afa_dataset_name = afa_dataset_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903ef5b-a358-4c83-91e5-6b6a3bd65d25",
   "metadata": {},
   "source": [
    "## Compute estimates for convergence\n",
    "If we know the ground truth, we might be interesting in plotting convergence, for this we might want to compute estimates J for different amount of available datapoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62750c70-9f2b-422c-a7ac-494b40ce21ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_models.afa_estimators.utils_static import define_afa_estimator_static\n",
    "from afa.afa_models.afa_estimators.utils import compute_counterfactual_cost_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "995a0b65-efd2-400d-8555-d7bbbb37f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init estiamtor \n",
    "estimators = [define_afa_estimator_static(    estimator_name   = mi_model_name ,\n",
    "                                              estimator_type   = 'simple_blocking' ,\n",
    "                                              estimator_params = None) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e168ea85-5048-41bf-9dea-91c709937860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate counterfactual average cost\n",
      "  - x-axis (number of datapoints) =  [ 10  53 280]\n",
      "  - number of bootstraps for estimation: 10\n"
     ]
    }
   ],
   "source": [
    "# define estimators \n",
    "J_bootstraps_convergence, convergence_steps  = compute_counterfactual_cost_convergence(  afa_dataset = afa_dataset, \n",
    "                                                                                         estimators = estimators, \n",
    "                                                                                         fold = 0, split = \"val\", \n",
    "                                                                                         n_samples = 1, \n",
    "                                                                                         n_bootstraps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8fc17b4-437f-46f4-8033-8b0857b08af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save estimators\n",
    "save_results_bootstrapping( J_bootstraps_convergence , agent_dir, convergence_steps = convergence_steps, afa_dataset_name = afa_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162dbbc-c7ca-4df4-836c-97c5908d0231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16412c37-7b97-44f9-a23b-ff4797bf67f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16cdb29-b320-440f-be38-6243324c7f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca79821-f118-48e6-80c5-e7d315409319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afa_env",
   "language": "python",
   "name": "afa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
