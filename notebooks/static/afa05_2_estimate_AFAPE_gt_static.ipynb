{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "767b7864-b3cf-4539-8227-c6de2ef7c792",
   "metadata": {},
   "source": [
    "# (5.2) Solve AFAPE for dataset created on ground truth data (no missingness) \n",
    "Use different estimators to compute E[C|do(R_bar = 1)]. Also give valid confidence intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b810b65-dcaa-4ad0-b0ed-cf3737fd8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96136052-0cbe-41a9-a69f-5e2de963a509",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25a07dc-1698-417c-9d75-a8d6323ca320",
   "metadata": {},
   "source": [
    "Paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99ec9cbe-dbdd-4b5c-891d-bcbdcbd398f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.configurations.utils_static import specify_default_paths_static\n",
    "# which dataset to work on \n",
    "dataset_name   = \"synthetic_1\"\n",
    "\n",
    "# automatically specify some path locations (change paths manually if needed) (WATCH OUT: LOAD ORIGINAL DATASET) \n",
    "paths = specify_default_paths_static(dataset_name = dataset_name , miss_scenario = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33a7fb8c-8fb9-4417-b4e1-9056bc328538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name for agent (and predictor) \n",
    "agent_name            = 'DQN'\n",
    "predictor_model_name  = 'logistic_regression'\n",
    "\n",
    "# name for of missingness scenario \n",
    "miss_scenario  = 'MCAR_1'\n",
    "\n",
    "# new (where to save the model) \n",
    "data_dir_models = '../../../data/static/' + dataset_name + '/' + miss_scenario + '/' # where are the models \n",
    "agent_dir           = data_dir_models  + 'afa_agents' + '/' + agent_name + '/'\n",
    "predictor_model_dir = data_dir_models  + 'predictor_models' + '/' + predictor_model_name + '/'\n",
    "\n",
    "# how to name the afa_dataset\n",
    "afa_dataset_name = 'ground_truth'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeebb97-1100-4f41-be81-63e6375a5f68",
   "metadata": {},
   "source": [
    "Define estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919fe648-3de4-4cea-9719-d79c72f40762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define estimators \n",
    "estimator_params_list = [\n",
    "        {'name': 'Ground_truth',\n",
    "        'estimator_type' : 'simple_blocking' }, \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04782040-9ef5-43e6-99b3-fc997fe88a62",
   "metadata": {},
   "source": [
    "## Load afa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e9d62da-8b4f-48e7-9f39-a635a95b65ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 18:41:47.672945: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-26 18:41:47.790744: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:47.790764: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-26 18:41:48.441688: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:48.441788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:48.441797: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from afa.data_modelling.datasets.data_loader.data_loader_static import DataLoader_static\n",
    "from afa.afa_datasets.afa_data_loader.afa_data_loader_static import AFADataLoader_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d3a81d-4bdf-4286-9645-097cee851433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "data_loader = DataLoader_static( data_file                  = paths['data_file'],\n",
    "                                 superfeature_mapping_file  = paths['superfeature_mapping_file'],\n",
    "                                 problem_file               = paths['problem_file'],\n",
    "                                 afa_problem_files          = paths['afa_problem_files'], \n",
    "                                 folds_file                 = paths['folds_file'] )\n",
    "dataset = data_loader.load() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5067e4d-de37-4fd6-8799-e783ad4792d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-26 18:41:53.726004: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-26 18:41:53.726146: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:53.726211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:53.726271: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:53.726331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:53.726389: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:53.726447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:53.726504: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:53.726561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-26 18:41:53.726570: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-26 18:41:53.726865: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#load afa_dataset\n",
    "augmented_data_file = agent_dir + afa_dataset_name + '_' + 'results.hkl'\n",
    "afa_agent_params = None\n",
    "afa_data_loader = AFADataLoader_static(                   \n",
    "                    augmented_data_file = augmented_data_file,\n",
    "                    dataset             = dataset,\n",
    "                    model_params        = afa_agent_params) \n",
    "afa_dataset = afa_data_loader.load() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8c7166-2fa0-4c7e-80b8-e678a6a5fdc6",
   "metadata": {},
   "source": [
    "## Initialize the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "978ab837-2b38-46ae-9259-c6faabc2b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_models.afa_estimators.utils_static import define_afa_estimator_static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24307ef-a9a7-4c3c-aa25-5cc8d007b8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = []\n",
    "for estimator_params in estimator_params_list:\n",
    "    estimator = define_afa_estimator_static(  estimator_name   = estimator_params['name'] ,\n",
    "                                              estimator_type   = estimator_params['estimator_type'] ,\n",
    "                                              estimator_params = estimator_params) \n",
    "    estimators.append(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c599147-ed2f-43a3-bba9-6d64167aa075",
   "metadata": {},
   "source": [
    "## Compute estimates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b388127c-1e11-4b50-86b5-3b68ac93baaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/mnt/c/Users/henrik.vonkleist/Nextcloud/PhD/Code/Active Feature Acquisition/afa_ts/afa/afa_models/afa_estimators/utils.py\u001b[0m(123)\u001b[0;36mbootstrap_ids\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    121 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    122 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 123 \u001b[0;31m    inds_bootstrapped_list = [    \n",
      "\u001b[0m\u001b[0;32m    124 \u001b[0;31m        \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_ids_subsample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap_inds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    125 \u001b[0;31m        \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bootstraps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  bootstrap_inds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[33, 21, 15, 33, 20,  3, 13, 26, 11, 39, 33,  6, 21, 28, 25, 22,\n",
      "         5,  2, 16, 17, 30, 35, 22,  3, 23, 36, 34, 27, 22, 10,  4,  9,\n",
      "         8, 21, 34,  9, 33, 33, 35,  3],\n",
      "       [23,  9, 27, 11, 15, 33,  2, 13, 22, 16, 38, 24, 15, 34, 39, 25,\n",
      "        10, 17, 22, 31, 37,  5, 10, 29, 30,  3, 11, 21, 22, 20, 27, 27,\n",
      "        22, 28, 26, 29, 39, 34, 28, 21],\n",
      "       [22, 22, 33, 38, 26, 15,  6, 31,  8, 35, 30,  3, 25,  0,  6,  2,\n",
      "        37, 18, 20, 36, 38,  7, 14, 12,  3,  2, 31,  7, 37, 11, 35,  6,\n",
      "         7, 11, 37, 12,  0,  4,  0, 19],\n",
      "       [24, 20, 14,  9, 20, 17, 38, 16, 39, 23, 21, 15,  2,  0,  5, 25,\n",
      "         6,  2, 27, 16,  2,  8, 27,  8, 28, 28, 18, 22, 18, 12, 31, 34,\n",
      "        24, 15, 35, 34, 30, 11, 12, 28],\n",
      "       [36, 34, 27, 21, 38, 11, 22,  2,  2, 38, 21, 28,  0, 39, 18, 22,\n",
      "        27, 33, 27, 21, 12, 16,  6, 30,  2, 15, 15, 14, 13, 34, 30,  9,\n",
      "        38, 28, 24,  2, 19,  6, 34, 21],\n",
      "       [ 6,  1, 27, 18, 17, 17, 36,  1, 27, 26,  4, 30, 15, 27, 32, 19,\n",
      "        28, 22, 19, 20, 18, 12,  2, 33, 22, 20, 13, 12, 11, 18,  3, 11,\n",
      "         7, 38, 38,  2, 33, 14,  9, 21],\n",
      "       [29, 32, 36,  9,  3, 11, 26, 28,  7,  6, 36,  5,  4, 16, 31, 20,\n",
      "        25, 22,  1,  4, 17, 13, 16,  8, 26, 16, 27, 29, 18, 10,  0, 22,\n",
      "        21, 12, 38, 24,  5, 22,  8,  6],\n",
      "       [19,  7, 24, 37, 17, 19, 28,  8, 11,  1,  9,  8, 27, 23,  9,  8,\n",
      "         5, 10, 33, 31, 13, 38,  5, 27,  0,  2, 13,  6, 23,  9,  2, 32,\n",
      "        13, 27, 31, 10, 23, 36, 16, 35],\n",
      "       [32, 39, 14, 10, 29, 18, 25,  8, 34,  3,  3,  3, 18, 25, 12, 38,\n",
      "        32, 12, 38, 26, 17, 15, 11, 17, 35, 20,  6, 14, 16,  5,  6, 19,\n",
      "        19, 28,  8, 13, 30, 25, 26, 24],\n",
      "       [16, 27,  9, 15, 16, 22,  9, 33,  5, 14, 18, 37, 20, 12, 19,  8,\n",
      "        18, 20, 24, 29, 35,  0,  9, 12, 33,  6, 35,  3,  8,  5, 27,  0,\n",
      "         3,  5,  8,  0,  9,  6, 29, 12]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  bootstrap_inds[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([33, 21, 15, 33, 20,  3, 13, 26, 11, 39, 33,  6, 21, 28, 25, 22,  5,\n",
      "        2, 16, 17, 30, 35, 22,  3, 23, 36, 34, 27, 22, 10,  4,  9,  8, 21,\n",
      "       34,  9, 33, 33, 35,  3])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  bootstrap_inds[0].shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40,)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  unique_ids_subsample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[89, 19,  5, 34, 57, 85, 98, 48, 68, 87, 33, 42, 99, 44, 24, 58,\n",
      "        22, 26, 49, 55, 47, 13, 90, 38, 84, 77, 92, 93, 82, 88, 83, 94,\n",
      "        54, 27, 95,  0, 20, 11, 71, 15],\n",
      "       [33, 54, 38, 26, 82, 34, 44, 95, 48, 57, 77, 19, 83, 87, 13, 94,\n",
      "        15, 27, 11, 24, 89,  5, 99, 20, 58, 71, 85, 47, 22, 68, 98, 84,\n",
      "        42, 93,  0, 92, 55, 90, 88, 49],\n",
      "       [68, 77, 99, 98, 13, 82, 38, 58, 44, 92, 57, 93, 24, 84, 85, 33,\n",
      "        19, 22, 11, 47, 89, 83, 48, 94, 87, 20, 26, 27, 49, 71, 90, 88,\n",
      "         0, 55, 54, 34, 42, 15, 95,  5],\n",
      "       [84, 87, 93, 68, 11, 54, 57, 83, 82, 22, 94, 42,  5, 88, 26, 98,\n",
      "        55, 44, 19, 47, 99, 90, 13, 85, 92,  0, 33, 49, 24, 48, 34, 27,\n",
      "        20, 95, 15, 89, 77, 58, 38, 71],\n",
      "       [99, 95, 49, 22, 13, 89, 87, 47, 93, 77, 58, 85,  5, 88, 82,  0,\n",
      "        42, 15, 68, 27, 11, 26, 54, 48, 84, 20, 55, 38, 34, 19, 71, 24,\n",
      "        57, 44, 90, 98, 83, 94, 33, 92],\n",
      "       [27, 48, 22, 47, 99, 90, 85, 71, 34, 92,  5, 83, 57, 58, 89, 54,\n",
      "        68, 38, 98, 82, 13,  0, 95, 19, 20, 33, 55, 88, 93, 44, 26, 11,\n",
      "        15, 42, 49, 94, 84, 77, 87, 24],\n",
      "       [44, 42, 89, 58, 19, 98, 92, 20, 34, 88, 83, 93, 26, 99, 77, 85,\n",
      "        68, 11,  5, 55, 13, 48, 22, 49, 27, 15, 47, 38, 95, 90, 94, 82,\n",
      "        33, 84, 24,  0, 57, 54, 71, 87],\n",
      "       [ 0, 92, 90, 84, 13, 94, 34, 22, 82, 44, 93, 33, 87, 95, 98, 71,\n",
      "        11, 88,  5, 48, 55, 15, 77, 20, 57, 89, 99, 42, 49, 19, 27, 58,\n",
      "        85, 54, 83, 68, 24, 38, 47, 26],\n",
      "       [34, 99, 82, 22, 20, 90, 98, 54, 92, 77, 68, 95, 19,  0, 44, 48,\n",
      "        27, 94, 15, 57, 58, 71, 88, 87, 38, 83, 11, 33, 55, 85, 24, 89,\n",
      "        47,  5, 13, 26, 42, 84, 93, 49],\n",
      "       [38, 99, 90, 49, 11, 27, 71, 22, 83, 24, 87, 57, 20, 19, 82, 94,\n",
      "        55, 85, 77, 48, 92, 33, 13, 93,  0, 95, 68, 58, 34, 26, 98, 88,\n",
      "        15, 44, 84, 54, 47,  5, 42, 89]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  unique_ids_subsample[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([89, 19,  5, 34, 57, 85, 98, 48, 68, 87, 33, 42, 99, 44, 24, 58, 22,\n",
      "       26, 49, 55, 47, 13, 90, 38, 84, 77, 92, 93, 82, 88, 83, 94, 54, 27,\n",
      "       95,  0, 20, 11, 71, 15])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "J_bootstraps = afa_dataset.estimate_counterfactual_cost( estimators = estimators, \n",
    "                                                         fold = 0, split = \"val\", \n",
    "                                                         n_samples = 1, \n",
    "                                                         n_bootstraps = 10, \n",
    "                                                         n_max = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78cb0c6-cb9e-4747-b91c-cfe3922d111f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ground_truth': array([1.51851852, 1.27272727, 1.18      , 1.15384615, 0.73076923,\n",
       "        1.61363636, 1.5       , 1.125     , 1.46296296, 0.77272727])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_bootstraps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44b918-5f45-41a3-9fff-00c1f24b49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save estimate\n",
    "from afa.afa_models.afa_estimators.utils import save_results_bootstrapping\n",
    "save_results_bootstrapping( J_bootstraps , agent_dir, afa_dataset_name = afa_dataset_name )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f903ef5b-a358-4c83-91e5-6b6a3bd65d25",
   "metadata": {},
   "source": [
    "## Compute estimates for convergence\n",
    "If we know the ground truth, we might be interesting in plotting convergence, for this we might want to compute estimates J for different amount of available datapoints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9ac90-eef9-408b-9bb9-b3189554fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_models.afa_estimators.utils import compute_counterfactual_cost_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e168ea85-5048-41bf-9dea-91c709937860",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_bootstraps_convergence, convergence_steps  = compute_counterfactual_cost_convergence(  afa_dataset = afa_dataset, \n",
    "                                                                                         estimators = estimators, \n",
    "                                                                                         fold = 0, split = \"val\", \n",
    "                                                                                         n_samples = 1, \n",
    "                                                                                         n_bootstraps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc17b4-437f-46f4-8033-8b0857b08af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save estimators\n",
    "save_results_bootstrapping( J_bootstraps_convergence , agent_dir, convergence_steps = convergence_steps, afa_dataset_name = afa_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9162dbbc-c7ca-4df4-836c-97c5908d0231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16412c37-7b97-44f9-a23b-ff4797bf67f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afa_env",
   "language": "python",
   "name": "afa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
