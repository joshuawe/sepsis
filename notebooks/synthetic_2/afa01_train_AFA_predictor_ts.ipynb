{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c30e44e-52d6-4634-b522-c267d9d25c18",
   "metadata": {},
   "source": [
    "# (1) Train predicator (classifier) for AFA \n",
    "The AFA problem contains the training of a classifier that is able to predict well based on any acquired subset of features. \n",
    "In this notebook we train and save such a classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ef781ed-4103-4ab3-9f58-0839da5b5655",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57977939-d5d3-4f0c-bd02-170beb177566",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de01ecb4-228b-4953-bca7-390eeeb74aa7",
   "metadata": {},
   "source": [
    "Paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48c5748-725f-4cc6-80b9-908f1b32664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.configurations.utils_ts import specify_default_paths_ts\n",
    "# which dataset to work on \n",
    "dataset_name   = \"synthetic_1\"\n",
    "\n",
    "# name for of missingness scenario \n",
    "miss_scenario  = 'MCAR_1'\n",
    "\n",
    "# automatically specify some path locations (change paths manually if needed) \n",
    "paths = specify_default_paths_ts(dataset_name = dataset_name , miss_scenario = miss_scenario) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86f309b-441c-4c0b-a6d8-89837df5a91f",
   "metadata": {},
   "source": [
    "Paths for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28e2e44-576f-4371-9ab8-001a0ab989e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name for predictor \n",
    "predictor_model_name  = 'logistic_regression'\n",
    "\n",
    "# new (where to save the model) \n",
    "predictor_model_dir = paths['data_dir'] + 'predictor_models' + '/' + predictor_model_name + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c26bb79-a599-4ec2-8714-395774f29e86",
   "metadata": {},
   "source": [
    "## Load dataset with missingness \n",
    "At first, we want to load the dataset \n",
    "\n",
    "Includes loading: \n",
    "- superfeature mapping\n",
    "- problem\n",
    "- afa_problem \n",
    "- missingness_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e389e952-73f7-4961-aaf3-7da80d5ebc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 18:35:23.180026: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 18:35:23.302390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:23.302410: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-27 18:35:23.977327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:23.977439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:23.977449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from afa.data_modelling.datasets.data_loader.data_loader_ts import DataLoader_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42cd08c0-44c4-4f01-88d7-33ccd11bc28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 739.26it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 860.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 699.38it/s]\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader_ts(     data_file                  = paths['data_file'],\n",
    "                                 temporal_data_file         = paths['temporal_data_file'],\n",
    "                                 superfeature_mapping_file  = paths['superfeature_mapping_file'],\n",
    "                                 problem_file               = paths['problem_file'],\n",
    "                                 afa_problem_files          = paths['afa_problem_files'], \n",
    "                                 miss_model_files           = paths['miss_model_files'], \n",
    "                                 folds_file                 = paths['folds_file'] )\n",
    "dataset = data_loader.load() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539523a-b1e7-4b8f-b010-3082ae3817ff",
   "metadata": {},
   "source": [
    "## Create afa dataset with missingness \n",
    "To train an AFA predictor, we need to induce artificial missingness (such that the predictor is robust to the missingness pattern). \n",
    "Here, we use a simple model to create missingness randomly (MCAR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f443fefb-ebed-4e35-bd9a-3b10988dc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_datasets.utils_ts import create_MCAR_afa_dataset_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f3bc2c-8c2c-407b-9d28-b8779a262a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change base_model to stationary_constant\n",
      "Change base_model to stationary_constant\n",
      "Set weight for constant stationary model ...\n",
      "Set weight for constant stationary model ...\n"
     ]
    }
   ],
   "source": [
    "afa_dataset = create_MCAR_afa_dataset_ts( dataset, MCAR_ratio = 0.9, n_samples = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25e9b6-f18b-47fb-9240-58efb84201ca",
   "metadata": {},
   "source": [
    "## Train Predictor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea987f31-febe-4053-9b9e-10dca7a72cfd",
   "metadata": {},
   "source": [
    "### Initialize predictor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39e3df59-098e-4ccb-a5ee-9ba6e9f0c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from afa.afa_models.afa_predictors.afa_predictor_ts import AFAPredictor_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4921f92-6e4c-49df-803a-682423b8e0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor_model_params = {\n",
    "    'name' : predictor_model_name, \n",
    "    'directory': predictor_model_dir,\n",
    "    'base_model_params' : {   'model_type': 'ImputeThenRegress',\n",
    "                              'imputer_params' : \n",
    "                                       {   \n",
    "                                      'model_type': 'simple_imputer',\n",
    "                                      'mode' : 'imputation'\n",
    "                                      },\n",
    "                              'predictor_params' : \n",
    "                                       {   \n",
    "                                      'model_type': 'ann',\n",
    "                                      'mode' : 'classification',\n",
    "                                      'units':              1,\n",
    "                                      'layers': 1,\n",
    "                                      'learning_rate': 0.01,\n",
    "                                      'batch_size' :128,\n",
    "                                      'epochs': 100 \n",
    "                                      }\n",
    "                          }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "399aeb50-ea4b-4d63-985d-b241a332e52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 18:35:29.799799: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-02-27 18:35:29.800132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:29.800302: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:29.800508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:29.800590: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:29.800670: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:29.800735: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:29.800799: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:29.800876: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:29.800891: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-27 18:35:29.801472: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "afa_predictor = AFAPredictor_ts(    name            = predictor_model_params['name'], \n",
    "                                    model_params    = predictor_model_params, \n",
    "                                    directory       = predictor_model_params['directory'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b521049-ef7e-4b80-8a50-015475834a14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 18:35:30.352021: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-02-27 18:35:30.352066: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2023-02-27 18:35:30.352152: I tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1664] Profiler found 1 GPUs\n",
      "2023-02-27 18:35:30.352864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so.11.2'; dlerror: libcupti.so.11.2: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:30.352999: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcupti.so'; dlerror: libcupti.so: cannot open shared object file: No such file or directory\n",
      "2023-02-27 18:35:30.353054: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: error 999: \n",
      "2023-02-27 18:35:30.353068: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2023-02-27 18:35:30.353072: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-02-27 18:35:30.353076: E tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1715] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2023-02-27 18:35:30.353232: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-02-27 18:35:30.353267: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2023-02-27 18:35:30.353273: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-02-27 18:35:30.353276: E tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1807] function cupti_interface_->Finalize()failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 205ms/step - loss: 0.7657 - binary_accuracy: 0.5444 - val_loss: 0.6088 - val_binary_accuracy: 0.6500\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.7547 - binary_accuracy: 0.5722 - val_loss: 0.6034 - val_binary_accuracy: 0.6500\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.7438 - binary_accuracy: 0.5833 - val_loss: 0.5982 - val_binary_accuracy: 0.6000\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.7328 - binary_accuracy: 0.5833 - val_loss: 0.5930 - val_binary_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7227 - binary_accuracy: 0.5889 - val_loss: 0.5877 - val_binary_accuracy: 0.6500\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7128 - binary_accuracy: 0.5889 - val_loss: 0.5826 - val_binary_accuracy: 0.6500\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7028 - binary_accuracy: 0.6000 - val_loss: 0.5776 - val_binary_accuracy: 0.6500\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6941 - binary_accuracy: 0.6056 - val_loss: 0.5731 - val_binary_accuracy: 0.7000\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6847 - binary_accuracy: 0.6111 - val_loss: 0.5686 - val_binary_accuracy: 0.7000\n",
      "Epoch 10/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6877 - binary_accuracy: 0.6094\n",
      "Epoch 10: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.6762 - binary_accuracy: 0.6111 - val_loss: 0.5642 - val_binary_accuracy: 0.7000\n",
      "Epoch 11/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6556 - binary_accuracy: 0.6484"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 18:35:31.748915: I tensorflow/core/profiler/lib/profiler_session.cc:101] Profiler session initializing.\n",
      "2023-02-27 18:35:31.749025: I tensorflow/core/profiler/lib/profiler_session.cc:116] Profiler session started.\n",
      "2023-02-27 18:35:31.749263: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-02-27 18:35:31.749288: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:184] cuptiSubscribe: ignored due to a previous error.\n",
      "2023-02-27 18:35:31.749293: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-02-27 18:35:31.749299: E tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1715] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6677 - binary_accuracy: 0.6111 - val_loss: 0.5599 - val_binary_accuracy: 0.7000\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6592 - binary_accuracy: 0.6278 - val_loss: 0.5558 - val_binary_accuracy: 0.7000\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6511 - binary_accuracy: 0.6333 - val_loss: 0.5520 - val_binary_accuracy: 0.7000\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6440 - binary_accuracy: 0.6444 - val_loss: 0.5485 - val_binary_accuracy: 0.7000\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6366 - binary_accuracy: 0.6500 - val_loss: 0.5451 - val_binary_accuracy: 0.7000\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6295 - binary_accuracy: 0.6722 - val_loss: 0.5418 - val_binary_accuracy: 0.7500\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6223 - binary_accuracy: 0.6611 - val_loss: 0.5385 - val_binary_accuracy: 0.7500\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6161 - binary_accuracy: 0.6667 - val_loss: 0.5351 - val_binary_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6096 - binary_accuracy: 0.6667 - val_loss: 0.5319 - val_binary_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6035 - binary_accuracy: 0.6722\n",
      "Epoch 20: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.6035 - binary_accuracy: 0.6722 - val_loss: 0.5289 - val_binary_accuracy: 0.7000\n",
      "Epoch 21/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.6207 - binary_accuracy: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 18:35:32.364071: I tensorflow/core/profiler/lib/profiler_session.cc:67] Profiler session collecting data.\n",
      "2023-02-27 18:35:32.364768: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:140] cuptiFinalize: ignored due to a previous error.\n",
      "2023-02-27 18:35:32.364814: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:457] cuptiGetResultString: ignored due to a previous error.\n",
      "2023-02-27 18:35:32.364824: E tensorflow/core/profiler/backends/gpu/cupti_tracer.cc:1807] function cupti_interface_->Finalize()failed with error \n",
      "2023-02-27 18:35:32.374886: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-02-27 18:35:32.374952: E tensorflow/core/profiler/backends/gpu/cupti_error_manager.cc:133] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2023-02-27 18:35:32.374965: I tensorflow/core/profiler/backends/gpu/cupti_collector.cc:522]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2023-02-27 18:35:32.376333: I tensorflow/core/profiler/lib/profiler_session.cc:128] Profiler session tear down.\n",
      "2023-02-27 18:35:32.406721: I tensorflow/core/profiler/rpc/client/save_profile.cc:164] Collecting XSpace to repository: ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/logs/20230227-183530/plugins/profile/2023_02_27_18_35_32/NB082969.xplane.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5978 - binary_accuracy: 0.6667 - val_loss: 0.5261 - val_binary_accuracy: 0.7000\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5922 - binary_accuracy: 0.6611 - val_loss: 0.5235 - val_binary_accuracy: 0.7000\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5869 - binary_accuracy: 0.6667 - val_loss: 0.5209 - val_binary_accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5818 - binary_accuracy: 0.6722 - val_loss: 0.5186 - val_binary_accuracy: 0.7000\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5766 - binary_accuracy: 0.6833 - val_loss: 0.5163 - val_binary_accuracy: 0.7000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5720 - binary_accuracy: 0.6833 - val_loss: 0.5142 - val_binary_accuracy: 0.7500\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5674 - binary_accuracy: 0.6833 - val_loss: 0.5122 - val_binary_accuracy: 0.7500\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5631 - binary_accuracy: 0.6889 - val_loss: 0.5102 - val_binary_accuracy: 0.7000\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5587 - binary_accuracy: 0.6889 - val_loss: 0.5083 - val_binary_accuracy: 0.7000\n",
      "Epoch 30/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5602 - binary_accuracy: 0.6719\n",
      "Epoch 30: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.5549 - binary_accuracy: 0.6889 - val_loss: 0.5064 - val_binary_accuracy: 0.7000\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5510 - binary_accuracy: 0.6889 - val_loss: 0.5047 - val_binary_accuracy: 0.7000\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5471 - binary_accuracy: 0.6889 - val_loss: 0.5027 - val_binary_accuracy: 0.7000\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5435 - binary_accuracy: 0.6944 - val_loss: 0.5010 - val_binary_accuracy: 0.7000\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5403 - binary_accuracy: 0.7000 - val_loss: 0.4994 - val_binary_accuracy: 0.7000\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5366 - binary_accuracy: 0.7000 - val_loss: 0.4978 - val_binary_accuracy: 0.7000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5335 - binary_accuracy: 0.7167 - val_loss: 0.4963 - val_binary_accuracy: 0.7000\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5303 - binary_accuracy: 0.7167 - val_loss: 0.4950 - val_binary_accuracy: 0.7000\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5274 - binary_accuracy: 0.7278 - val_loss: 0.4937 - val_binary_accuracy: 0.7000\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5242 - binary_accuracy: 0.7278 - val_loss: 0.4927 - val_binary_accuracy: 0.7000\n",
      "Epoch 40/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5298 - binary_accuracy: 0.7188\n",
      "Epoch 40: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.5213 - binary_accuracy: 0.7222 - val_loss: 0.4917 - val_binary_accuracy: 0.7000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5186 - binary_accuracy: 0.7278 - val_loss: 0.4909 - val_binary_accuracy: 0.7000\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5162 - binary_accuracy: 0.7278 - val_loss: 0.4900 - val_binary_accuracy: 0.7000\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5135 - binary_accuracy: 0.7333 - val_loss: 0.4890 - val_binary_accuracy: 0.7000\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5112 - binary_accuracy: 0.7333 - val_loss: 0.4880 - val_binary_accuracy: 0.7000\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5086 - binary_accuracy: 0.7333 - val_loss: 0.4869 - val_binary_accuracy: 0.7000\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5064 - binary_accuracy: 0.7389 - val_loss: 0.4858 - val_binary_accuracy: 0.7000\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5042 - binary_accuracy: 0.7333 - val_loss: 0.4847 - val_binary_accuracy: 0.7000\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5022 - binary_accuracy: 0.7333 - val_loss: 0.4835 - val_binary_accuracy: 0.7000\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5001 - binary_accuracy: 0.7333 - val_loss: 0.4822 - val_binary_accuracy: 0.7000\n",
      "Epoch 50/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5082 - binary_accuracy: 0.7188\n",
      "Epoch 50: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.4982 - binary_accuracy: 0.7333 - val_loss: 0.4810 - val_binary_accuracy: 0.7000\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4963 - binary_accuracy: 0.7278 - val_loss: 0.4798 - val_binary_accuracy: 0.7000\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4944 - binary_accuracy: 0.7333 - val_loss: 0.4787 - val_binary_accuracy: 0.7000\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4927 - binary_accuracy: 0.7389 - val_loss: 0.4775 - val_binary_accuracy: 0.7000\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4909 - binary_accuracy: 0.7389 - val_loss: 0.4765 - val_binary_accuracy: 0.7000\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4894 - binary_accuracy: 0.7389 - val_loss: 0.4754 - val_binary_accuracy: 0.7000\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4878 - binary_accuracy: 0.7389 - val_loss: 0.4743 - val_binary_accuracy: 0.7000\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4862 - binary_accuracy: 0.7444 - val_loss: 0.4734 - val_binary_accuracy: 0.7000\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4848 - binary_accuracy: 0.7500 - val_loss: 0.4724 - val_binary_accuracy: 0.7000\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4833 - binary_accuracy: 0.7500 - val_loss: 0.4715 - val_binary_accuracy: 0.7000\n",
      "Epoch 60/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4993 - binary_accuracy: 0.7422\n",
      "Epoch 60: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.4819 - binary_accuracy: 0.7556 - val_loss: 0.4707 - val_binary_accuracy: 0.7000\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4805 - binary_accuracy: 0.7556 - val_loss: 0.4699 - val_binary_accuracy: 0.7000\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4792 - binary_accuracy: 0.7556 - val_loss: 0.4692 - val_binary_accuracy: 0.7000\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4779 - binary_accuracy: 0.7556 - val_loss: 0.4686 - val_binary_accuracy: 0.7000\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4766 - binary_accuracy: 0.7556 - val_loss: 0.4679 - val_binary_accuracy: 0.7000\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4755 - binary_accuracy: 0.7556 - val_loss: 0.4672 - val_binary_accuracy: 0.7000\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4743 - binary_accuracy: 0.7556 - val_loss: 0.4666 - val_binary_accuracy: 0.7000\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4732 - binary_accuracy: 0.7556 - val_loss: 0.4659 - val_binary_accuracy: 0.7000\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4721 - binary_accuracy: 0.7556 - val_loss: 0.4653 - val_binary_accuracy: 0.7000\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4710 - binary_accuracy: 0.7611 - val_loss: 0.4648 - val_binary_accuracy: 0.7000\n",
      "Epoch 70/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4869 - binary_accuracy: 0.7578\n",
      "Epoch 70: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.4700 - binary_accuracy: 0.7611 - val_loss: 0.4642 - val_binary_accuracy: 0.7000\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4690 - binary_accuracy: 0.7667 - val_loss: 0.4637 - val_binary_accuracy: 0.7000\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4680 - binary_accuracy: 0.7722 - val_loss: 0.4632 - val_binary_accuracy: 0.7000\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4672 - binary_accuracy: 0.7722 - val_loss: 0.4625 - val_binary_accuracy: 0.7000\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4662 - binary_accuracy: 0.7667 - val_loss: 0.4617 - val_binary_accuracy: 0.7000\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4653 - binary_accuracy: 0.7667 - val_loss: 0.4611 - val_binary_accuracy: 0.7000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4644 - binary_accuracy: 0.7667 - val_loss: 0.4606 - val_binary_accuracy: 0.7000\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4636 - binary_accuracy: 0.7611 - val_loss: 0.4601 - val_binary_accuracy: 0.7000\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4628 - binary_accuracy: 0.7611 - val_loss: 0.4597 - val_binary_accuracy: 0.7000\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4620 - binary_accuracy: 0.7611 - val_loss: 0.4593 - val_binary_accuracy: 0.7000\n",
      "Epoch 80/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4579 - binary_accuracy: 0.7656\n",
      "Epoch 80: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.4613 - binary_accuracy: 0.7556 - val_loss: 0.4591 - val_binary_accuracy: 0.7000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.4605 - binary_accuracy: 0.7556 - val_loss: 0.4589 - val_binary_accuracy: 0.7000\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4599 - binary_accuracy: 0.7556 - val_loss: 0.4588 - val_binary_accuracy: 0.7000\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4593 - binary_accuracy: 0.7556 - val_loss: 0.4586 - val_binary_accuracy: 0.7000\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.4586 - binary_accuracy: 0.7611 - val_loss: 0.4583 - val_binary_accuracy: 0.7000\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4579 - binary_accuracy: 0.7556 - val_loss: 0.4581 - val_binary_accuracy: 0.7000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4574 - binary_accuracy: 0.7556 - val_loss: 0.4581 - val_binary_accuracy: 0.7000\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4568 - binary_accuracy: 0.7556 - val_loss: 0.4578 - val_binary_accuracy: 0.7000\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4563 - binary_accuracy: 0.7556 - val_loss: 0.4575 - val_binary_accuracy: 0.7000\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4557 - binary_accuracy: 0.7611 - val_loss: 0.4573 - val_binary_accuracy: 0.7000\n",
      "Epoch 90/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4276 - binary_accuracy: 0.7812\n",
      "Epoch 90: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.4551 - binary_accuracy: 0.7611 - val_loss: 0.4569 - val_binary_accuracy: 0.7000\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4547 - binary_accuracy: 0.7611 - val_loss: 0.4565 - val_binary_accuracy: 0.7000\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4541 - binary_accuracy: 0.7611 - val_loss: 0.4559 - val_binary_accuracy: 0.7000\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4537 - binary_accuracy: 0.7611 - val_loss: 0.4551 - val_binary_accuracy: 0.7000\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4532 - binary_accuracy: 0.7611 - val_loss: 0.4545 - val_binary_accuracy: 0.7000\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4528 - binary_accuracy: 0.7611 - val_loss: 0.4538 - val_binary_accuracy: 0.7000\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4522 - binary_accuracy: 0.7611 - val_loss: 0.4534 - val_binary_accuracy: 0.7500\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4518 - binary_accuracy: 0.7611 - val_loss: 0.4530 - val_binary_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4513 - binary_accuracy: 0.7611 - val_loss: 0.4527 - val_binary_accuracy: 0.7500\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4509 - binary_accuracy: 0.7611 - val_loss: 0.4525 - val_binary_accuracy: 0.7000\n",
      "Epoch 100/100\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4503 - binary_accuracy: 0.7578\n",
      "Epoch 100: saving model to ../../../data/ts/synthetic_1/MCAR_1/predictor_models/logistic_regression/cp.ckpt\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4505 - binary_accuracy: 0.7611 - val_loss: 0.4523 - val_binary_accuracy: 0.7000\n",
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "afa_predictor.fit(afa_dataset, \n",
    "                  fold = 0, \n",
    "                  train_split = 'train', \n",
    "                  valid_split = 'val', \n",
    "                  fit_again = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9df65e1c-7a7b-472f-9234-8e4e0b075e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "label_pred = afa_predictor.predict( afa_dataset, fold = 0, split = 'val', n_samples = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02de1750-1f77-4c11-87ad-a7036d4984ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 5, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b54ad5d-82f9-492d-b2ff-f91e4047aee3",
   "metadata": {},
   "source": [
    "### Write report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d7bfd91-a0d0-45c7-b95a-182c528d3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_file = afa_predictor.directory + 'model_report.md'  # +  'reports/' + 'model_report' \n",
    "afa_predictor.explain(file= explanation_file, format = 'markdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f649d771-b660-4218-9327-2166d2b3417f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afa_env",
   "language": "python",
   "name": "afa_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
