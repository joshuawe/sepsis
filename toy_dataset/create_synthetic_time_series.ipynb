{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We want to create a synthetic time series data set\n",
    "\n",
    "> Based on the synthetic data generation notebook of the ```afa``` repository by Henrik von Kleist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home2/joshua.wendland/Documents/sepsis/toy_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 12:47:56.559341: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-28 12:47:56.559367: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "relative_path_to_afa = '../../afa_github/afa'\n",
    "#sys.path.insert(0, os.path.abspath(relative_path_to_afa))\n",
    "sys.path.insert(1, os.path.join(sys.path[0], relative_path_to_afa))\n",
    "print('CWD:', pathlib.Path(pathlib.Path.cwd()))\n",
    "\n",
    "import sklearn\n",
    "\n",
    "# data generation\n",
    "from afa_datasets.synthetic_data.data_generation_ts import generate_data_ts\n",
    "\n",
    "# loading/ saving\n",
    "from data_modelling.clairvoyance_static.datasets.data_loader import CSVLoader, save_dataset\n",
    "from data_modelling.clairvoyance_static.utils.model_utils import PipelineComposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "data_dir = \"dataset/\"\n",
    "dataset_name = \"synthetic_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datageneration\n",
    "\n",
    "Use sklearn's make-classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_test = generate_data_ts(data_dir = data_dir + dataset_name + \"/\", \n",
    "#                                          dataset_name = dataset_name,\n",
    "#                                          n_features_static  = 4 ,\n",
    "#                                          n_features_ts  = 10 ,\n",
    "#                                          n_redundant = 0 ,\n",
    "#                                          n_informative = 2,\n",
    "#                                          n_datapts   = 200000,\n",
    "#                                          n_classes   = 2,\n",
    "#                                          random_state  = 47,\n",
    "#                                          test_size   = 0.5)\n",
    "\n",
    "data_train_ts_df, data_train_static_df, data_test_ts_df, data_test_static_df = generate_data_ts(data_dir = \"\",\n",
    "                                        dataset_name = \"synthetic_ts_1\",\n",
    "                                        n_features_static  = 2  ,\n",
    "                                        n_features_ts      = 4  , \n",
    "                                        n_timepts   = 50,\n",
    "                                        n_datapts   = 100, \n",
    "                                        test_size = 0.1,\n",
    "                                        table_style = 'wide',\n",
    "                                        n_classes   = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "\n",
    "+ First import necessary stuff.\n",
    "+ Look at simple implementations on how to handle the data\n",
    "+ Then use ```Dataset``` class from Pytorch to handle the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and show the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         id  time    X_ts_0    X_ts_1    X_ts_2    X_ts_3      Y_ts\n",
      "0    id_90     0  0.627422 -0.478959 -0.892121 -0.318527  1.083295\n",
      "1    id_90     1 -0.448220  0.019303 -0.127440 -0.157412  1.093168\n",
      "2    id_90     2  0.637957 -0.386629 -0.416992  0.772078  1.026738\n",
      "3    id_90     3  0.114574 -0.700368  0.415711 -0.584559  0.891013\n",
      "4    id_90     4  0.318873  0.112828  0.575051  0.149870  0.813476\n",
      "..     ...   ...       ...       ...       ...       ...       ...\n",
      "495  id_99    45  0.033853  0.889838  0.867147 -0.226947  0.981591\n",
      "496  id_99    46 -0.883889  1.506605  0.732750  0.466535  0.846787\n",
      "497  id_99    47  1.267585 -0.623064  0.034502 -0.162447  0.901342\n",
      "498  id_99    48 -1.544032  0.310212  1.469414  0.941757  0.912135\n",
      "499  id_99    49  1.052585 -0.451113  1.395424 -0.229020  0.822956\n",
      "\n",
      "[500 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "path = '/home2/joshua.wendland/Documents/sepsis/toy_dataset/synthetic_ts_1/synthetic_ts_test_data_eav.csv.gz'\n",
    "\n",
    "df = pd.read_csv(path, compression=None)\n",
    "df = df.sort_values(by=['id', 'time'], ascending=True, ignore_index=True)  # time was not sorted\n",
    "\n",
    "print(df.head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data according to each ```id``` of the time series. \n",
    "This is easily done by using the ```groupby()``` method on the DataFrame. This transforms the data into the structure of:\n",
    "\n",
    "| Group Name (or ID) | Pandas Series   |  \n",
    "| ------------------ | --------------- |\n",
    "| id_0              | Series of id_0 |  \n",
    "| id_1              | Series of id_1 |  \n",
    "| ...              | ... |  \n",
    "\n",
    "To receive a certain Series ID ```i``` we just need to call ```df_grouped[i, 0]```.\n",
    "To receive the corresponding Series data we call ```df_grouped[i, 1]```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time    X_ts_0    X_ts_1    X_ts_2    X_ts_3      Y_ts\n",
      "450     0  2.715997  0.325934 -0.486907 -2.543788  1.054109\n",
      "451     1  1.526065  1.121756 -0.514032 -0.396498  0.764149\n",
      "452     2 -0.505807  0.863921  0.798771 -0.444982  1.008917\n",
      "453     3  0.788786  0.825285  0.303744 -1.426538  0.986686\n",
      "454     4  0.219992 -0.188746 -0.861897 -0.611712  0.816993\n",
      "     time    X_ts_0    X_ts_1    X_ts_2    X_ts_3      Y_ts\n",
      "495    45  0.033853  0.889838  0.867147 -0.226947  0.981591\n",
      "496    46 -0.883889  1.506605  0.732750  0.466535  0.846787\n",
      "497    47  1.267585 -0.623064  0.034502 -0.162447  0.901342\n",
      "498    48 -1.544032  0.310212  1.469414  0.941757  0.912135\n",
      "499    49  1.052585 -0.451113  1.395424 -0.229020  0.822956\n"
     ]
    }
   ],
   "source": [
    "# Group by 'id'\n",
    "df_grouped = pd.DataFrame(df.groupby('id'))\n",
    "# Get rid of the 'id'-column in each group\n",
    "for x in df_grouped.iloc[:,1]:\n",
    "    x.drop(columns=['id'], inplace=True)\n",
    "    \n",
    "print(df_grouped.iloc[-1,1].head())\n",
    "print(df_grouped.iloc[-1,1].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[    time    X_ts_0    X_ts_1    X_ts_2    X_ts_3      Y_ts\n",
       "        0      0  0.627422 -0.478959 -0.892121 -0.318527  1.083295\n",
       "        1      1 -0.448220  0.019303 -0.127440 -0.157412  1.093168\n",
       "        2      2  0.637957 -0.386629 -0.416992  0.772078  1.026738\n",
       "        3      3  0.114574 -0.700368  0.415711 -0.584559  0.891013\n",
       "        4      4  0.318873  0.112828  0.575051  0.149870  0.813476\n",
       "        5      5 -0.558442  2.029959  0.012359 -1.908553  0.898056\n",
       "        6      6  0.939696  0.830056 -0.280783 -0.986594  0.935163\n",
       "        7      7 -0.797461 -1.047239 -1.473412 -0.771835  0.762820\n",
       "        8      8  1.885109 -0.629077 -1.387293 -0.917362  0.842649\n",
       "        9      9 -1.015954  0.494451 -0.388469 -0.276064  1.019764\n",
       "        10    10  0.468969 -0.523529 -0.680064  0.181355  0.972393\n",
       "        11    11 -1.567821 -1.188615 -0.513788 -0.120319  0.855685\n",
       "        12    12  0.788097  0.687057 -1.804858 -0.250144  1.185819\n",
       "        13    13 -0.467239  1.484642 -0.442640  0.049348  0.892820\n",
       "        14    14 -1.067668 -1.508826  0.293647 -0.323093  0.587973\n",
       "        15    15 -0.510791  0.332147  0.384341  1.424772  0.854223\n",
       "        16    16  1.760742  0.215419  0.210296  0.943911  0.925794\n",
       "        17    17 -1.129330  0.329094  0.698252  0.077501  0.894323\n",
       "        18    18 -1.245252 -0.386010 -0.290340 -0.724083  0.763535\n",
       "        19    19  0.374238  0.793722 -0.989127 -0.240775  1.037749\n",
       "        20    20  0.229987  2.403446  0.458991 -0.701644  0.845908\n",
       "        21    21 -1.956168  0.638526 -1.802841 -0.013752  0.838975\n",
       "        22    22 -0.285089  0.728738 -0.285939  0.860865  0.781228\n",
       "        23    23 -0.127742 -0.130743 -0.030715  0.990276  0.879172\n",
       "        24    24 -0.653852 -0.702537 -0.636888  0.622586  0.819381\n",
       "        25    25 -1.942277 -2.129068 -0.285234 -0.009707  0.572855\n",
       "        26    26 -0.832058  0.606369  0.585842 -0.460500  0.901710\n",
       "        27    27 -0.045629  1.159174  1.109582  0.478892  0.811241\n",
       "        28    28 -0.034631 -0.287276  0.056000  0.079586  0.964252\n",
       "        29    29  0.365976 -0.479471 -0.770567 -0.059988  0.904866\n",
       "        30    30  1.714363 -0.678394 -0.453063  0.568113  1.103889\n",
       "        31    31 -0.264306 -0.480000 -0.329321  0.372906  0.859776\n",
       "        32    32 -0.066568  0.284823  0.486283  1.027146  0.626287\n",
       "        33    33 -0.480193  0.511479 -0.042283  0.085692  1.023365\n",
       "        34    34  0.443927  0.259823  0.896139 -0.527713  0.898980\n",
       "        35    35 -0.305377 -1.048794  1.279945  0.853433  0.930392\n",
       "        36    36 -0.693766  0.265684  1.045459  0.754092  0.848467\n",
       "        37    37 -0.280872 -0.623445  0.140099  0.348989  1.058388\n",
       "        38    38  0.795986 -0.780048  0.714222 -0.412215  0.855220\n",
       "        39    39 -0.597815  0.187230  0.784806 -0.534255  0.842808\n",
       "        40    40 -0.510641  0.732767  0.326506 -0.123117  0.982704\n",
       "        41    41  0.687088 -0.259999  0.817837  0.260476  0.751696\n",
       "        42    42  1.571823 -0.188101  0.475608  0.815023  0.836356\n",
       "        43    43  0.366849 -0.259040 -0.441317 -1.370295  0.818246\n",
       "        44    44  1.533595 -0.255016 -0.195798 -0.000594  0.943086\n",
       "        45    45 -1.178103  0.014941  0.880480 -0.775395  0.945845\n",
       "        46    46 -0.915174  0.504395 -0.639835 -0.831032  0.598867\n",
       "        47    47  0.273137 -0.350031 -0.300115 -0.030460  0.913727\n",
       "        48    48 -0.997676  0.362155 -0.067811 -0.446476  1.012348\n",
       "        49    49 -0.678586  0.935433  0.097610  0.262062  0.889169],\n",
       "       [    time    X_ts_0    X_ts_1    X_ts_2    X_ts_3      Y_ts\n",
       "        50     0 -0.449281 -1.248403 -0.593112  0.834997  0.813850\n",
       "        51     1 -0.226785 -1.531340  1.564129  0.104404  0.981473\n",
       "        52     2 -0.867711 -0.059777  0.011100 -0.034776  0.919398\n",
       "        53     3 -3.379370  1.673227  0.313718 -0.922119  0.714324\n",
       "        54     4  0.950942  0.028739  0.389454 -0.467543  0.841035\n",
       "        55     5 -0.099637 -0.484731  0.071699  0.031150  1.033901\n",
       "        56     6 -0.947260 -0.416571 -1.048014 -0.707633  0.758310\n",
       "        57     7 -0.428362 -0.421424  1.199600 -1.340726  0.867259\n",
       "        58     8  0.176000 -0.905108  0.046784 -0.450768  0.939735\n",
       "        59     9  0.614216 -0.421048 -0.561949 -0.244719  0.867658\n",
       "        60    10  0.990403 -0.491733 -0.254210 -2.679163  0.746678\n",
       "        61    11 -1.934945 -0.590803  0.721213 -1.792950  0.749980\n",
       "        62    12  0.528473  1.215816 -1.390006 -0.303868  1.049134\n",
       "        63    13 -1.386807 -1.093617  0.270134 -0.221077  0.916458\n",
       "        64    14 -0.678054 -1.854658 -0.563822  0.023340  0.712821\n",
       "        65    15  0.984116  1.434620 -0.243789 -0.032222  0.770656\n",
       "        66    16  0.171493 -0.875114  0.148238  0.099392  0.985597\n",
       "        67    17  0.772320 -0.094864  1.210078 -0.327951  0.912266\n",
       "        68    18  0.528869 -1.342999 -0.954070  0.730435  0.935660\n",
       "        69    19 -0.554059  0.108604 -1.329769 -0.169643  0.992338\n",
       "        70    20 -0.112124 -0.553016 -1.236752 -0.120470  0.797127\n",
       "        71    21 -0.174758 -1.524750  0.077580  0.343801  0.837464\n",
       "        72    22 -0.271905  0.384169 -0.050325  0.715713  1.016607\n",
       "        73    23  0.078379  0.277747  0.106750 -0.248417  1.090376\n",
       "        74    24 -0.335977 -0.385198  0.462252 -0.125656  1.045343\n",
       "        75    25  1.204533  0.373539  0.561009 -1.265501  0.866590\n",
       "        76    26  0.197843 -0.326253  0.549060  0.302315  0.960605\n",
       "        77    27  0.379184  0.848978 -0.279495 -0.469841  0.962197\n",
       "        78    28 -0.684971 -2.078374 -0.281104 -0.421101  0.633678\n",
       "        79    29 -1.444822  1.460976 -0.754764 -0.228540  0.808062\n",
       "        80    30 -1.129839  0.211828 -0.511313  0.482281  0.981203\n",
       "        81    31  0.996169 -0.356047  1.135093  0.541813  0.758796\n",
       "        82    32 -0.409594  0.062126  0.865331 -1.144999  0.997452\n",
       "        83    33 -0.537697  0.074821  0.228533  0.134374  1.158640\n",
       "        84    34  1.606665  0.096568 -2.264828 -0.053329  1.132503\n",
       "        85    35  0.910075 -1.079377 -0.948879  0.113248  1.048677\n",
       "        86    36 -0.105233  0.326639 -0.779221 -0.322681  0.903519\n",
       "        87    37  0.312277 -0.593688 -0.104060  0.578403  0.869403\n",
       "        88    38 -0.446513 -0.681270  1.231852  0.973131  0.856389\n",
       "        89    39 -0.082401 -1.854463 -0.206348 -1.147457  0.751362\n",
       "        90    40 -0.442821 -0.063255  0.687160 -1.195592  0.886954\n",
       "        91    41 -1.934059 -0.462677  1.279317  0.475645  0.894044\n",
       "        92    42 -0.000343  1.179582  0.727603 -0.436994  0.921693\n",
       "        93    43  1.406584 -0.703028 -0.117706  0.494629  1.048501\n",
       "        94    44  1.443758 -1.448727 -0.556694 -0.106901  1.042223\n",
       "        95    45  1.519221  0.521160  0.055834 -0.973976  0.849438\n",
       "        96    46  0.527446  0.618777  0.096691 -1.903165  1.067588\n",
       "        97    47  0.820195  0.905821 -0.887097 -1.358582  0.980968\n",
       "        98    48 -0.513682 -0.711065  0.192354 -0.845454  0.860885\n",
       "        99    49  1.271258 -0.401188 -0.012843  0.164233  0.978888]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_grouped.drop(columns=0).to_numpy(copy=True)\n",
    "\n",
    "\n",
    "X = df_grouped.drop(columns=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Pytorch class ```Dataset``` and ```Dataloader```\n",
    "\n",
    "+ First import necessary modules.\n",
    "+ Implement the ```Dataset``` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m T \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(df_grouped\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mto_numpy(copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "class ToyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        df = pd.read_csv(path, compression=None)\n",
    "        df = df.sort_values(by=['id', 'time'], ascending=True, ignore_index=True)  # time was not sorted\n",
    "        # Number of samples\n",
    "        self.n_samples = df['id'].unique()\n",
    "        # Group by ID\n",
    "        df_grouped = pd.DataFrame(df.groupby('id'))\n",
    "        # Get rid of the 'id'-column in each group\n",
    "        for x in df_grouped.iloc[:,1]:\n",
    "            x.drop(columns=['id'], inplace=True)\n",
    "\n",
    "        X = df_grouped.drop(columns=0).to_numpy(copy=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('mTAN': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c0149bcba5d57c6c5fe6ec16c81707307f68ffca57204c4f3e4ca3000c08467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
