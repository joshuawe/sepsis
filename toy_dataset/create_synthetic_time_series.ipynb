{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We want to create a synthetic time series data set\n",
    "\n",
    "> Based on the synthetic data generation notebook of the ```afa``` repository by Henrik von Kleist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /home2/joshua.wendland/Documents/sepsis/toy_dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 12:47:56.559341: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-28 12:47:56.559367: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "relative_path_to_afa = '../../afa_github/afa'\n",
    "#sys.path.insert(0, os.path.abspath(relative_path_to_afa))\n",
    "sys.path.insert(1, os.path.join(sys.path[0], relative_path_to_afa))\n",
    "print('CWD:', pathlib.Path(pathlib.Path.cwd()))\n",
    "\n",
    "import sklearn\n",
    "\n",
    "# data generation\n",
    "from afa_datasets.synthetic_data.data_generation_ts import generate_data_ts\n",
    "\n",
    "# loading/ saving\n",
    "from data_modelling.clairvoyance_static.datasets.data_loader import CSVLoader, save_dataset\n",
    "from data_modelling.clairvoyance_static.utils.model_utils import PipelineComposer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories\n",
    "data_dir = \"dataset/\"\n",
    "dataset_name = \"synthetic_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datageneration\n",
    "\n",
    "Use sklearn's make-classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train, df_test = generate_data_ts(data_dir = data_dir + dataset_name + \"/\", \n",
    "#                                          dataset_name = dataset_name,\n",
    "#                                          n_features_static  = 4 ,\n",
    "#                                          n_features_ts  = 10 ,\n",
    "#                                          n_redundant = 0 ,\n",
    "#                                          n_informative = 2,\n",
    "#                                          n_datapts   = 200000,\n",
    "#                                          n_classes   = 2,\n",
    "#                                          random_state  = 47,\n",
    "#                                          test_size   = 0.5)\n",
    "\n",
    "data_train_ts_df, data_train_static_df, data_test_ts_df, data_test_static_df = generate_data_ts(data_dir = \"\",\n",
    "                                        dataset_name = \"synthetic_ts_1\",\n",
    "                                        n_features_static  = 2  ,\n",
    "                                        n_features_ts      = 4  , \n",
    "                                        n_timepts   = 50,\n",
    "                                        n_datapts   = 100, \n",
    "                                        test_size = 0.1,\n",
    "                                        table_style = 'wide',\n",
    "                                        n_classes   = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "\n",
    "First import necessary stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and show the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         id  time    X_ts_0    X_ts_1    X_ts_2    X_ts_3      Y_ts\n",
      "0    id_90     0  0.627422 -0.478959 -0.892121 -0.318527  1.083295\n",
      "1    id_90     1 -0.448220  0.019303 -0.127440 -0.157412  1.093168\n",
      "2    id_90     2  0.637957 -0.386629 -0.416992  0.772078  1.026738\n",
      "3    id_90     3  0.114574 -0.700368  0.415711 -0.584559  0.891013\n",
      "4    id_90     4  0.318873  0.112828  0.575051  0.149870  0.813476\n",
      "..     ...   ...       ...       ...       ...       ...       ...\n",
      "495  id_99    45  0.033853  0.889838  0.867147 -0.226947  0.981591\n",
      "496  id_99    46 -0.883889  1.506605  0.732750  0.466535  0.846787\n",
      "497  id_99    47  1.267585 -0.623064  0.034502 -0.162447  0.901342\n",
      "498  id_99    48 -1.544032  0.310212  1.469414  0.941757  0.912135\n",
      "499  id_99    49  1.052585 -0.451113  1.395424 -0.229020  0.822956\n",
      "\n",
      "[500 rows x 7 columns]>\n"
     ]
    }
   ],
   "source": [
    "path = '/home2/joshua.wendland/Documents/sepsis/toy_dataset/synthetic_ts_1/synthetic_ts_test_data_eav.csv.gz'\n",
    "\n",
    "df = pd.read_csv(path, compression=None)\n",
    "df = df.sort_values(by=['id', 'time'], ascending=True, ignore_index=True)  # time was not sorted\n",
    "\n",
    "print(df.head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data according to each ```id``` of the time series. \n",
    "This is easily done by using the ```groupby()``` method on the DataFrame. This transforms the data into the structure of:\n",
    "\n",
    "| Group Name (or ID) | Pandas Series   |  \n",
    "| ------------------ | --------------- |\n",
    "| id_90              | Series of id_90 |  \n",
    "| id_91              | Series of id_91 |  \n",
    "| ...              | ... |  \n",
    "\n",
    "To receive a certain Series ID ```i``` we just need to call ```df_grouped[i, 0]```.\n",
    "To receive the corresponding Series data we call ```df_grouped[i, 1]```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  time    X_ts_0    X_ts_1    X_ts_2    X_ts_3      Y_ts\n",
      "450  id_99     0  2.715997  0.325934 -0.486907 -2.543788  1.054109\n",
      "451  id_99     1  1.526065  1.121756 -0.514032 -0.396498  0.764149\n",
      "452  id_99     2 -0.505807  0.863921  0.798771 -0.444982  1.008917\n",
      "453  id_99     3  0.788786  0.825285  0.303744 -1.426538  0.986686\n",
      "454  id_99     4  0.219992 -0.188746 -0.861897 -0.611712  0.816993\n",
      "455  id_99     5  0.672091 -0.404279  0.618024  0.522364  0.920787\n",
      "456  id_99     6  0.464268  0.104738 -0.546725  0.383898  0.977540\n",
      "457  id_99     7  0.548396  0.713342 -0.406693  0.639087  0.967501\n",
      "458  id_99     8 -0.340459  0.572502 -0.176726 -0.006179  1.087702\n",
      "459  id_99     9 -0.469286 -0.352744  0.543369  0.351378  1.037535\n",
      "460  id_99    10  0.238644  0.439631  0.560051 -0.179127  0.892054\n",
      "461  id_99    11 -1.408751  0.395566 -1.982116  1.018491  0.731176\n",
      "462  id_99    12 -0.774979  1.008667 -0.172575  0.717566  0.888754\n",
      "463  id_99    13  0.269323 -1.244125 -0.206261  1.513991  0.810245\n",
      "464  id_99    14  0.077563  0.464741  1.874135  0.876204  0.702494\n",
      "465  id_99    15  0.836966  0.837505  0.499820  0.370485  0.738574\n",
      "466  id_99    16 -1.928973 -0.927773  0.068372  1.044701  0.791166\n",
      "467  id_99    17 -0.300769 -0.882740 -1.088331  0.799000  0.804466\n",
      "468  id_99    18  0.336874 -0.805070 -0.324278 -0.586627  0.791563\n",
      "469  id_99    19  0.581269 -0.516314  0.081706 -1.038163  0.939955\n",
      "470  id_99    20  1.356864 -0.182995  0.191167 -1.192758  1.061950\n",
      "471  id_99    21 -0.449333  0.901041 -0.517749 -0.957298  0.724265\n",
      "472  id_99    22  0.370224 -0.153162 -0.316084 -1.519673  0.884602\n",
      "473  id_99    23 -0.919908  2.446664  1.682576 -0.986124  0.802458\n",
      "474  id_99    24  1.244830 -0.674030  1.125629 -1.003254  1.091343\n",
      "475  id_99    25  1.914538 -0.364017 -0.027507 -0.630641  1.043400\n",
      "476  id_99    26  0.234703  0.280728 -0.750381 -0.625746  1.049466\n",
      "477  id_99    27 -2.193904  0.452244  0.636986 -0.568580  0.773781\n",
      "478  id_99    28 -0.164145  2.361896  0.157410 -0.385576  0.683573\n",
      "479  id_99    29 -1.374415  0.123966  0.549533  0.220215  0.915599\n",
      "480  id_99    30  0.429214 -0.453875 -0.599523  0.163621  0.847747\n",
      "481  id_99    31  0.726589  0.278990 -0.068756  1.386344  0.902517\n",
      "482  id_99    32 -1.235710 -0.443321  0.375419  1.174394  0.952672\n",
      "483  id_99    33 -0.178207  1.217088  0.429119 -0.110166  0.814355\n",
      "484  id_99    34 -1.222342 -1.134144 -0.570384  0.504013  0.724296\n",
      "485  id_99    35 -1.209311 -0.585504 -0.878792  1.191613  1.030616\n",
      "486  id_99    36  0.522876  0.163937  0.029741 -0.547223  1.162016\n",
      "487  id_99    37 -0.527510 -0.672664 -1.082727  0.660433  0.820351\n",
      "488  id_99    38 -1.340989 -0.142871 -0.772623  0.326456  0.930322\n",
      "489  id_99    39  2.964444 -0.046726 -0.603796  0.672963  0.866981\n",
      "490  id_99    40 -2.152870 -1.413736 -1.827767 -0.165091  0.777002\n",
      "491  id_99    41 -1.025784 -1.302681  0.454961 -0.266070  0.917962\n",
      "492  id_99    42  0.578635  2.214691 -0.759585  0.546953  0.671664\n",
      "493  id_99    43  0.610938  1.318253 -0.659503 -0.174893  1.026326\n",
      "494  id_99    44  1.342411  0.130822  0.350150 -1.003846  0.991342\n",
      "495  id_99    45  0.033853  0.889838  0.867147 -0.226947  0.981591\n",
      "496  id_99    46 -0.883889  1.506605  0.732750  0.466535  0.846787\n",
      "497  id_99    47  1.267585 -0.623064  0.034502 -0.162447  0.901342\n",
      "498  id_99    48 -1.544032  0.310212  1.469414  0.941757  0.912135\n",
      "499  id_99    49  1.052585 -0.451113  1.395424 -0.229020  0.822956\n"
     ]
    }
   ],
   "source": [
    "df_grouped = pd.DataFrame(df.groupby('id'))\n",
    "print(df_grouped.iloc[-1,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('datasetEnv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cbfaf034946b7253fac58ddaedd665a3b3e64e59160ad1e3c4d801657dd0a95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
